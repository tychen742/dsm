{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a Jupyter Notebook\n",
    "\n",
    "A Jupyter Notebook is a data-science environment that combines:\n",
    "\n",
    "1. **Narrative:** The text describing your analysis\n",
    "2. **Code:** The program that does the analysis\n",
    "3. **Results:** The output of the program\n",
    "\n",
    "The Jupyter environment was created by faculty here at Berkeley (Fernando Perez). These ideas are now in a lot of different technologies (e.g., Google Collab). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Example\n",
    "\n",
    "**Note:** In this lecture there is a lot of code. You are not expected to know any of this yet. This is just a preview of the things you will see in the next few weeks. \n",
    "\n",
    "<br/><br/><br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the tools of data science to study text.  For example, here we will do some basic analysis of *[\"Adventures of Huckleberry Finn\"](https://en.wikipedia.org/wiki/Adventures_of_Huckleberry_Finn)* (by Mark Twain) and from *[\"Little Women\"](https://en.wikipedia.org/wiki/Little_Women)* (by Louisa May Alcott).  \n",
    "\n",
    "Often the first step in data sciences is getting the data.  The following is a tiny program to download text from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tiny program to download text from the web.\n",
    "def read_url(url): \n",
    "    from urllib.request import urlopen \n",
    "    import re\n",
    "    return re.sub('\\\\s+', ' ', urlopen(url, context = context).read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we download the books from the data8 textbook website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "huck_finn_url = 'https://www.inferentialthinking.com/data/huck_finn.txt'\n",
    "huck_finn_text = read_url(huck_finn_url)\n",
    "huck_finn_chapters = huck_finn_text.split('CHAPTER ')[44:]\n",
    "# huck_finn_chapters = urlopen(huck_finn_url, context=context).read().decode().split('CHAPTER ')[44:]\n",
    "# chapters = urlopen(little_women_url, context=context).read().decode().split('CHAPTER ')[1:]\n",
    "# little_women_url = 'https://www.introdsm.org/data/little_women.txt'\n",
    "# chapters = urlopen(little_women_url, context=context).read().decode().split('CHAPTER ')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "little_women_url = 'https://www.inferentialthinking.com/data/little_women.txt'\n",
    "little_women_text = read_url(little_women_url)\n",
    "little_women_chapters = little_women_text.split('CHAPTER ')[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the text from the first chapter of Huckleberry Finn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Chapters</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>I. YOU don't know about me without you have read a book  ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>II. WE went tiptoeing along a path amongst the trees bac ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>III. WELL, I got a good going-over in the morning from o ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>IV. WELL, three or four months run along, and it was wel ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>V. I had shut the door to. Then I turned around and ther ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>VI. WELL, pretty soon the old man was up and around agai ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>VII. \"GIT up! What you 'bout?\" I opened my eyes and look ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>VIII. THE sun was up so high when I waked that I judged  ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>IX. I wanted to go and look at a place right about the m ...</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>X. AFTER breakfast I wanted to talk about the dead man a ...</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (33 rows omitted)</p>"
      ],
      "text/plain": [
       "Chapters\n",
       "I. YOU don't know about me without you have read a book  ...\n",
       "II. WE went tiptoeing along a path amongst the trees bac ...\n",
       "III. WELL, I got a good going-over in the morning from o ...\n",
       "IV. WELL, three or four months run along, and it was wel ...\n",
       "V. I had shut the door to. Then I turned around and ther ...\n",
       "VI. WELL, pretty soon the old man was up and around agai ...\n",
       "VII. \"GIT up! What you 'bout?\" I opened my eyes and look ...\n",
       "VIII. THE sun was up so high when I waked that I judged  ...\n",
       "IX. I wanted to go and look at a place right about the m ...\n",
       "X. AFTER breakfast I wanted to talk about the dead man a ...\n",
       "... (33 rows omitted)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write some code here\n",
    "from datascience import *\n",
    "Table().with_column('Chapters', huck_finn_chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Tables\n",
    "\n",
    "A lot of data science is about transforming data often to produce tables that we can more easily analyze.\n",
    "In this class you will use the Berkeley datascience library to manipulate and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datascience\n",
    "datascience.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Chapters', huck_finn_chapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore data by extracting summaries. For example, we might ask, how often characters appeared in each chapter. We can use snippets of code to answer these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.char.count(huck_finn_chapters, 'Tom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.char.count(huck_finn_chapters, 'Jim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the results of our analysis into more tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Table().with_columns([\n",
    "    'Tom', np.char.count(huck_finn_chapters, 'Tom'),\n",
    "    'Jim', np.char.count(huck_finn_chapters, 'Jim'),\n",
    "    'Huck', np.char.count(huck_finn_chapters, 'Huck'),\n",
    "])\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/>\n",
    "\n",
    "\n",
    "# We will Learn to Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the cumulative counts:\n",
    "How many times in Chapter 1, how many times in Chapters 1 and 2, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "cum_counts_tom = np.cumsum(counts.column(\"Tom\"))\n",
    "cum_counts_jim = np.cumsum(counts.column(\"Jim\"))\n",
    "cum_counts_huck = np.cumsum(counts.column(\"Huck\"))\n",
    "cumulative_table = Table().with_columns(\n",
    "    'Chapter', np.arange(1, 44, 1),\n",
    "    'Tom', cum_counts_tom,\n",
    "    'Jim', cum_counts_jim,\n",
    "    'Huck', cum_counts_huck\n",
    ")\n",
    "cumulative_table.plot(column_for_xticks='Chapter')\n",
    "plt.title('Cumulative Number of Times Name Appears')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we tell from this visualization?  What questions does this raise?\n",
    "\n",
    "\n",
    "<br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chapters of Little Women\n",
    "Table().with_column('Chapters', little_women_chapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/>\n",
    "\n",
    "We can explore the characters in Little Women using the same kind of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of names in the chapters of Little Women\n",
    "names = ['Amy', 'Beth', 'Jo', 'Laurie', 'Meg']\n",
    "mentions = {name: np.char.count(little_women_chapters, name) for name in names}\n",
    "counts = Table().with_columns([\n",
    "        'Amy', mentions['Amy'],\n",
    "        'Beth', mentions['Beth'],\n",
    "        'Jo', mentions['Jo'],\n",
    "        'Laurie', mentions['Laurie'],\n",
    "        'Meg', mentions['Meg']\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative counts\n",
    "cum_counts_amy = np.cumsum(counts.column(\"Amy\"))\n",
    "cum_counts_beth = np.cumsum(counts.column(\"Beth\"))\n",
    "cum_counts_jo = np.cumsum(counts.column(\"Jo\"))\n",
    "cum_counts_laurie = np.cumsum(counts.column(\"Laurie\"))\n",
    "cum_counts_meg = np.cumsum(counts.column(\"Meg\"))\n",
    "\n",
    "cumulative_table = Table().with_columns(\n",
    "    'Chapter', np.arange(1, 48, 1),\n",
    "    'Amy', cum_counts_amy,\n",
    "    'Beth', cum_counts_beth,\n",
    "    'Jo', cum_counts_jo,\n",
    "    'Laurie', cum_counts_laurie,\n",
    "    'Meg', cum_counts_meg\n",
    ")\n",
    "\n",
    "cumulative_table.plot(column_for_xticks='Chapter')\n",
    "plt.title('Cumulative Number of Times Names Appear in Little Women')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use interactive tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative counts\n",
    "Table.interactive_plots()\n",
    "cumulative_table.plot(column_for_xticks=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/> \n",
    "\n",
    "---\n",
    "\n",
    "# Examining Length\n",
    "\n",
    "How long are the books? How long are sentences?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(read_url(huck_finn_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In each chapter, count the number of all characters;\n",
    "# call this the \"length\" of the chapter.\n",
    "# Also count the number of periods.\n",
    "\n",
    "length_hf = Table().with_columns([\n",
    "        'Length', [len(s) for s in huck_finn_chapters],\n",
    "        'Periods', np.char.count(huck_finn_chapters, '.')\n",
    "    ])\n",
    "length_lw = Table().with_columns([\n",
    "        'Length', [len(s) for s in little_women_chapters],\n",
    "        'Periods', np.char.count(little_women_chapters, '.')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The counts for Huckleberry Finn\n",
    "length_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The counts for Little Women\n",
    "length_lw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table.static_plots()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(length_hf[1], length_hf[0], color='darkblue')\n",
    "plt.scatter(length_lw[1], length_lw[0], color='gold')\n",
    "plt.xlabel('Number of periods in chapter')\n",
    "plt.ylabel('Number of characters in chapter');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Examining distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table.static_plots()\n",
    "length_hf.with_columns(\"Sentence Length\", length_hf['Length']/length_hf['Periods']).hist(\"Sentence Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table.static_plots()\n",
    "length_lw.with_columns(\"Sentence Length\", length_lw['Length']/length_lw['Periods']).hist(\"Sentence Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf21ed8e1a65c559da2cb273a11174743e2e2b37c54da2273cb868ae002ee465"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
