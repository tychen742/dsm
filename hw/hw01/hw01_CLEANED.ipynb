{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebd291d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw01.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646fa207",
   "metadata": {},
   "source": [
    "# Homework 1: Causality and Expressions\n",
    "\n",
    "Please complete this notebook by filling in the cells provided. Before you begin, run the previous cell to load the provided tests."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3b08451",
   "metadata": {},
   "source": [
    "**Recommended Readings:**\n",
    "\n",
    "- [What is Data Science?](http://dsm.org/chapters/01/what-is-data-science.html)\n",
    "- [Causality and Experiments](http://dsm.org/chapters/02/causality-and-experiments.html) \n",
    "- [Programming in Python](http://dsm.org/chapters/03/programming-in-python.html)\n",
    "\n",
    "For all problems that you must write explanations and sentences for, \n",
    "- you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, please\n",
    "- be sure to **not re-assign variables** throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!\n",
    "\n",
    "**Note: This homework has hidden tests on it. That means even though tests may say 100% passed, it doesn't mean your final grade will be 100%. We will be running more hidden tests for correctness once everyone turns in the homework.**\n",
    "\n",
    "- Directly sharing answers is not okay, but\n",
    "- discussing problems with the course staff or with other students is encouraged.\n",
    "- Learn cooperatively; **DO NOT CHEAT**.\n",
    "- You should start early in the assignment cycle so that you have time to get help.\n",
    "- If you're stuck, come to the help sessions/office hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bc819",
   "metadata": {},
   "source": [
    "## 1. Scary Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02440ac5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.1** An ad for ADT Security Systems says,\n",
    "\n",
    "> \"When you go on vacation, burglars go to work [...] According to FBI statistics, over 25% of home burglaries occur between Memorial Day to Labor Day.\"\n",
    "\n",
    "Do the data in the ad support the claim that burglars are more likely to go to work during the time between Memorial Day to Labor Day? Please explain your answer. **(6 Points)**\n",
    "\n",
    "**Note:** You can assume that \"over 25%\" means only slightly over. Had it been much over, say closer to 30%, then the marketers would have said so.\n",
    "\n",
    "**Note:** Memorial Day is observed on the last Monday of May and Labor Day is observed on the first Monday of September.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25330a56",
   "metadata": {},
   "source": [
    "No it does not. It's a period of a little more than 3 months, about 25% of a year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f2ca7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 2. Characters in Little Women\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19196e25",
   "metadata": {},
   "source": [
    "In lecture, we counted the number of times that the literary characters were named in each chapter of the classic book, [*Little Women*](https://inferentialthinking.com/chapters/01/3/1/Literary_Characters.html?highlight=little%20women). In computer science, the word \"character\" also refers to a letter, digit, space, or punctuation mark; any single element of a text. The following code generates a scatter plot in which each dot corresponds to a chapter of *Little Women*. The horizontal position of a dot measures the number of periods in the chapter. The vertical position measures the total number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd09440",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just run this cell.\n",
    "\n",
    "# This cell contains code that hasn't yet been covered in the course,\n",
    "# but you should be able to interpret the scatter plot it generates.\n",
    "\n",
    "from datascience import *\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import ssl\n",
    "%matplotlib inline\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "\n",
    "little_women_url = 'https://www.introdsm.org/data/little_women.txt'\n",
    "chapters = urlopen(little_women_url, context=context).read().decode().split('CHAPTER ')[1:]\n",
    "text = Table().with_column('Chapters', chapters)\n",
    "Table().with_columns(\n",
    "    'Periods',    np.char.count(chapters, '.'),\n",
    "    'Characters', text.apply(len, 0)\n",
    "    ).scatter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720546cf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** Around how many periods are there in the chapter with the most characters? Assign either 1, 2, 3, 4, or 5 to the name `characters_q1` below. **(4 Points)**\n",
    "\n",
    "1. 250\n",
    "2. 390\n",
    "3. 440\n",
    "4. 32,000\n",
    "5. 40,000\n",
    "\n",
    "\n",
    "**Note:** If you run into a `NameError: name 'grader' is not defined` error in the autograder cell below (and in any assignment), please re-run the first cell at the very top of this notebook!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bac3d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "characters_q1 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62eb07d0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Test q2_1 not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq2_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/check/utils.py:242\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_event(event_type, success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     ret \u001b[38;5;241m=\u001b[39m LoggedEventReturnValue(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/check/utils.py:238\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03mRuns a method, catching any errors and logging the call. Returns the unwrapped return value\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03mof the wrapped function.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     ret: Optional[LoggedEventReturnValue[T]] \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_event(event_type, success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/check/notebook.py:286\u001b[0m, in \u001b[0;36mNotebook.check\u001b[0;34m(self, question, global_env)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# run the check\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling checker\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 286\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mChecker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nbmeta_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LoggedEventReturnValue(result, question\u001b[38;5;241m=\u001b[39mquestion, shelve_env\u001b[38;5;241m=\u001b[39mglobal_env)\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/execute/checker.py:80\u001b[0m, in \u001b[0;36mChecker.check\u001b[0;34m(cls, nb_or_test_path, nbmeta_config, test_name, global_env)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck\u001b[39m(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     global_env: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     65\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TestFile:\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    Checks a global environment against a test, which may be stored in a file or in a notebook's\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    metadata.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m        given global environment\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     test \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_test_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_or_test_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbmeta_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m global_env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m         global_env \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\u001b[38;5;241m.\u001b[39mf_back\u001b[38;5;241m.\u001b[39mf_globals\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/test_files/__init__.py:63\u001b[0m, in \u001b[0;36mcreate_test_file\u001b[0;34m(path, nbmeta_config, test_name)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m NotebookMetadataOKTestFile\u001b[38;5;241m.\u001b[39mfrom_nbmeta_config(path, nbmeta_config, test_name)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNotebookMetadataExceptionTestFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_nbmeta_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbmeta_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m env \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/test_files/metadata_test.py:54\u001b[0m, in \u001b[0;36m_NotebookMetadataTestFileMixin.from_nbmeta_config\u001b[0;34m(cls, path, nbmeta_config, test_name)\u001b[0m\n\u001b[1;32m     52\u001b[0m test_spec \u001b[38;5;241m=\u001b[39m nbmeta_config\u001b[38;5;241m.\u001b[39mtests\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m test_spec:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m test_spec \u001b[38;5;241m=\u001b[39m test_spec[test_name]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_metadata(test_spec, path\u001b[38;5;241m=\u001b[39mpath)\n",
      "\u001b[0;31mValueError\u001b[0m: Test q2_1 not found"
     ]
    }
   ],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9bb10e",
   "metadata": {},
   "source": [
    "The test above checks that your answers are in the correct format. **This test does not check that you answered correctly**, only that you assigned a number successfully in each multiple-choice answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639eeb1a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Which of the following chapters has the most characters per period? Assign either 1, 2, or 3 to the name `characters_q2` below. **(4 Points)**\n",
    "\n",
    "1. The chapter with about 60 periods\n",
    "2. The chapter with about 350 periods\n",
    "3. The chapter with about 440 periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "227f9a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "characters_q2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcef0ec9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Test q2_2 not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq2_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/check/utils.py:242\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_event(event_type, success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     ret \u001b[38;5;241m=\u001b[39m LoggedEventReturnValue(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/check/utils.py:238\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03mRuns a method, catching any errors and logging the call. Returns the unwrapped return value\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03mof the wrapped function.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     ret: Optional[LoggedEventReturnValue[T]] \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_event(event_type, success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/check/notebook.py:286\u001b[0m, in \u001b[0;36mNotebook.check\u001b[0;34m(self, question, global_env)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# run the check\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling checker\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 286\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mChecker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nbmeta_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LoggedEventReturnValue(result, question\u001b[38;5;241m=\u001b[39mquestion, shelve_env\u001b[38;5;241m=\u001b[39mglobal_env)\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/execute/checker.py:80\u001b[0m, in \u001b[0;36mChecker.check\u001b[0;34m(cls, nb_or_test_path, nbmeta_config, test_name, global_env)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck\u001b[39m(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     global_env: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     65\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TestFile:\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    Checks a global environment against a test, which may be stored in a file or in a notebook's\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    metadata.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m        given global environment\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     test \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_test_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_or_test_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbmeta_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m global_env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m         global_env \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\u001b[38;5;241m.\u001b[39mf_back\u001b[38;5;241m.\u001b[39mf_globals\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/test_files/__init__.py:63\u001b[0m, in \u001b[0;36mcreate_test_file\u001b[0;34m(path, nbmeta_config, test_name)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m NotebookMetadataOKTestFile\u001b[38;5;241m.\u001b[39mfrom_nbmeta_config(path, nbmeta_config, test_name)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNotebookMetadataExceptionTestFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_nbmeta_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbmeta_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m env \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/test_files/metadata_test.py:54\u001b[0m, in \u001b[0;36m_NotebookMetadataTestFileMixin.from_nbmeta_config\u001b[0;34m(cls, path, nbmeta_config, test_name)\u001b[0m\n\u001b[1;32m     52\u001b[0m test_spec \u001b[38;5;241m=\u001b[39m nbmeta_config\u001b[38;5;241m.\u001b[39mtests\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m test_spec:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m test_spec \u001b[38;5;241m=\u001b[39m test_spec[test_name]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_metadata(test_spec, path\u001b[38;5;241m=\u001b[39mpath)\n",
      "\u001b[0;31mValueError\u001b[0m: Test q2_2 not found"
     ]
    }
   ],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb1ddd",
   "metadata": {},
   "source": [
    "Again, the test above checks that your answers are in the correct format, but not that you have answered correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3d6fa",
   "metadata": {},
   "source": [
    "To discover more interesting facts from this plot, check out [Section 1.3.2](https://inferentialthinking.com/chapters/01/3/2/Another_Kind_Of_Character.html) in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29ee66d",
   "metadata": {},
   "source": [
    "## 3. Names and Assignment Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ef513",
   "metadata": {},
   "source": [
    "**Question 1.** When you run the following cell, Python produces a cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1826cd63",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal here. Maybe you meant '==' instead of '='? (2912417615.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    4 = 2 + 2\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to literal here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "4 = 2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a4f9ed",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Choose the best explanation of what's wrong with the code, and then assign 1, 2, 3, or 4 to `names_q1` below to indicate your answer. **(4 Points)**\n",
    "\n",
    "1. Python is smart and already knows `4 = 2 + 2`.\n",
    "\n",
    "2. In Python, it's a rule that the `=` sign must have a variable name to its left, and `4` isn't a variable name.\n",
    "\n",
    "3. It should be `2 + 2 = 4`.\n",
    "\n",
    "4. I don't get an error message. This is a trick question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "effd15e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names_q1 = 2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73986866",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Test q3_1 not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq3_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/check/utils.py:242\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_event(event_type, success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     ret \u001b[38;5;241m=\u001b[39m LoggedEventReturnValue(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/check/utils.py:238\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03mRuns a method, catching any errors and logging the call. Returns the unwrapped return value\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03mof the wrapped function.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     ret: Optional[LoggedEventReturnValue[T]] \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_event(event_type, success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/check/notebook.py:286\u001b[0m, in \u001b[0;36mNotebook.check\u001b[0;34m(self, question, global_env)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# run the check\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling checker\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 286\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mChecker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nbmeta_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LoggedEventReturnValue(result, question\u001b[38;5;241m=\u001b[39mquestion, shelve_env\u001b[38;5;241m=\u001b[39mglobal_env)\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/execute/checker.py:80\u001b[0m, in \u001b[0;36mChecker.check\u001b[0;34m(cls, nb_or_test_path, nbmeta_config, test_name, global_env)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck\u001b[39m(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     global_env: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     65\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TestFile:\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    Checks a global environment against a test, which may be stored in a file or in a notebook's\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    metadata.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m        given global environment\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     test \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_test_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_or_test_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbmeta_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m global_env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m         global_env \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\u001b[38;5;241m.\u001b[39mf_back\u001b[38;5;241m.\u001b[39mf_globals\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/test_files/__init__.py:63\u001b[0m, in \u001b[0;36mcreate_test_file\u001b[0;34m(path, nbmeta_config, test_name)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m NotebookMetadataOKTestFile\u001b[38;5;241m.\u001b[39mfrom_nbmeta_config(path, nbmeta_config, test_name)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNotebookMetadataExceptionTestFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_nbmeta_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbmeta_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m env \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/workspace/introdsm/.venv/lib/python3.12/site-packages/otter/test_files/metadata_test.py:54\u001b[0m, in \u001b[0;36m_NotebookMetadataTestFileMixin.from_nbmeta_config\u001b[0;34m(cls, path, nbmeta_config, test_name)\u001b[0m\n\u001b[1;32m     52\u001b[0m test_spec \u001b[38;5;241m=\u001b[39m nbmeta_config\u001b[38;5;241m.\u001b[39mtests\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m test_spec:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m test_spec \u001b[38;5;241m=\u001b[39m test_spec[test_name]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_metadata(test_spec, path\u001b[38;5;241m=\u001b[39mpath)\n",
      "\u001b[0;31mValueError\u001b[0m: Test q3_1 not found"
     ]
    }
   ],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae3c85",
   "metadata": {},
   "source": [
    "**Question 2.** When you run the following cell, Python will produce another cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f48fe5a6",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3853341378.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    six = two plus two\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "two = 3\n",
    "six = two plus two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb8c8f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Choose the best explanation of what's wrong with the code and assign 1, 2, 3, or 4 to `names_q2` below to indicate your answer. **(4 Points)**\n",
    "\n",
    "1. The `plus` operation only applies to numbers, not the word \"two\".\n",
    "\n",
    "2. The name \"two\" cannot be assigned to the number 3.\n",
    "\n",
    "3. Two plus two is four, not six.\n",
    "\n",
    "4. The name `plus` isn't a built-in operator; instead, addition uses `+`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00dec41e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names_q2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f63273ff",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q3_2</pre> results:</strong></p><p><strong><pre style='display: inline;'>q3_2 - 1</pre> result:</strong></p><pre>     Test case failed\n",
       "    Trying:\n",
       "        1 <= names_q2 <= 4\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q3_2 0\n",
       "    Failed example:\n",
       "        1 <= names_q2 <= 4\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "            ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                         compileflags, True), test.globs)\n",
       "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "          File \"<doctest q3_2 0[0]>\", line 1, in <module>\n",
       "            1 <= names_q2 <= 4\n",
       "                 ^^^^^^^^\n",
       "        NameError: name 'names_q2' is not defined\n",
       "</pre>"
      ],
      "text/plain": [
       "q3_2 results:\n",
       "    q3_2 - 1 result:\n",
       "         Test case failed\n",
       "        Trying:\n",
       "            1 <= names_q2 <= 4\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q3_2 0\n",
       "        Failed example:\n",
       "            1 <= names_q2 <= 4\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q3_2 0[0]>\", line 1, in <module>\n",
       "                1 <= names_q2 <= 4\n",
       "                     ^^^^^^^^\n",
       "            NameError: name 'names_q2' is not defined"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0c2a5",
   "metadata": {},
   "source": [
    "**Question 3.** Run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34baca81",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "x = 2\n",
    "y = 3 * x\n",
    "x = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e46e874",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What is `y` after running this cell, and why? Choose the best explanation and assign 1, 2, 3, or 4 to `names_q3` below to indicate your answer. **(4 Points)**\n",
    "\n",
    "1. `y` is equal to 6, because the second `x = 4` has no effect since `x` was already defined.\n",
    "\n",
    "2. `y` is equal to 6, because `x` was 2 when `y` was assigned, and 3 * 2 is 6.\n",
    "\n",
    "3. `y` is equal to 12, because `x` is 4 and 3 * 4 is 12.\n",
    "\n",
    "4. `y` is equal to 12, because assigning `x` to 4 will update `y` to 12 since `y` was defined in terms of `x`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c70ce3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names_q3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50e5e2f5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q3_3</pre> results:</strong></p><p><strong><pre style='display: inline;'>q3_3 - 1</pre> result:</strong></p><pre>     Test case failed\n",
       "    Trying:\n",
       "        1 <= names_q3 <= 4\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q3_3 0\n",
       "    Failed example:\n",
       "        1 <= names_q3 <= 4\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "            ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                         compileflags, True), test.globs)\n",
       "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "          File \"<doctest q3_3 0[0]>\", line 1, in <module>\n",
       "            1 <= names_q3 <= 4\n",
       "                 ^^^^^^^^\n",
       "        NameError: name 'names_q3' is not defined\n",
       "</pre>"
      ],
      "text/plain": [
       "q3_3 results:\n",
       "    q3_3 - 1 result:\n",
       "         Test case failed\n",
       "        Trying:\n",
       "            1 <= names_q3 <= 4\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q3_3 0\n",
       "        Failed example:\n",
       "            1 <= names_q3 <= 4\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q3_3 0[0]>\", line 1, in <module>\n",
       "                1 <= names_q3 <= 4\n",
       "                     ^^^^^^^^\n",
       "            NameError: name 'names_q3' is not defined"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b45634",
   "metadata": {},
   "source": [
    "## 4. Differences Between Majors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf0a57",
   "metadata": {},
   "source": [
    "Berkeleys Office of Planning and Analysis (OPA) provides data on numerous aspects of the campus. Adapted from the OPA website, the table below displays the number of degree recipients in three majors in the 2008-2009 and 2017-2018 academic years.\n",
    "\n",
    "| Major                              | 2008-2009    | 2017-2018   |\n",
    "|------------------------------------|--------------|-------------|\n",
    "| Gender and Women's Studies         |      17      |    28       |\n",
    "| Linguistics                        |      49      |    67       |\n",
    "| Rhetoric                           |      113     |    56       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0edcd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** Suppose you want to find the **biggest** absolute difference between the number of degree recipients in the two years, among the three majors.\n",
    "\n",
    "In the cell below, compute this value and call it `biggest_change`. Use a single expression (a single line of code) to compute the answer. Let Python perform all the arithmetic (like subtracting 49 from 67) rather than simplifying the expression yourself. The built-in `abs` function takes a numerical input and returns the absolute value. The built-in `max` function can take in 3 arguments and returns the maximum of the three numbers. **(5 Points)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e7df660",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggest_change = ...\n",
    "biggest_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac4b16d3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q4_1</pre> results:</strong></p><p><strong><pre style='display: inline;'>q4_1 - 1</pre> result:</strong></p><pre>     Test case failed\n",
       "    Trying:\n",
       "        isinstance(biggest_change, (int, float))\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q4_1 0\n",
       "    Failed example:\n",
       "        isinstance(biggest_change, (int, float))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "            ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                         compileflags, True), test.globs)\n",
       "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "          File \"<doctest q4_1 0[0]>\", line 1, in <module>\n",
       "            isinstance(biggest_change, (int, float))\n",
       "                       ^^^^^^^^^^^^^^\n",
       "        NameError: name 'biggest_change' is not defined\n",
       "</pre>"
      ],
      "text/plain": [
       "q4_1 results:\n",
       "    q4_1 - 1 result:\n",
       "         Test case failed\n",
       "        Trying:\n",
       "            isinstance(biggest_change, (int, float))\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q4_1 0\n",
       "        Failed example:\n",
       "            isinstance(biggest_change, (int, float))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q4_1 0[0]>\", line 1, in <module>\n",
       "                isinstance(biggest_change, (int, float))\n",
       "                           ^^^^^^^^^^^^^^\n",
       "            NameError: name 'biggest_change' is not defined"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb8f4c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Which of the three majors had the **smallest** absolute difference? Assign `smallest_change_major` to 1, 2, or 3 where each number corresponds to the following major:\n",
    "\n",
    "1. Gender and Women's Studies  \n",
    "2. Linguistics  \n",
    "3. Rhetoric\n",
    "\n",
    "Choose the number that corresponds to the major with the smallest absolute difference. **(4 Points)** \n",
    "\n",
    "_Hint:_ You should be able to answer by rough mental arithmetic, without having to calculate the exact value for each major.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec1c3033",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest_change_major = ...\n",
    "smallest_change_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38a0d407",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q4_2</pre> results:</strong></p><p><strong><pre style='display: inline;'>q4_2 - 1</pre> result:</strong></p><pre>     Test case failed\n",
       "    Trying:\n",
       "        isinstance(smallest_change_major, (int, float))\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q4_2 0\n",
       "    Failed example:\n",
       "        isinstance(smallest_change_major, (int, float))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "            ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                         compileflags, True), test.globs)\n",
       "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "          File \"<doctest q4_2 0[0]>\", line 1, in <module>\n",
       "            isinstance(smallest_change_major, (int, float))\n",
       "                       ^^^^^^^^^^^^^^^^^^^^^\n",
       "        NameError: name 'smallest_change_major' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q4_2 - 2</pre> result:</strong></p><pre>     Test case failed\n",
       "    Trying:\n",
       "        1 <= smallest_change_major <= 3\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q4_2 1\n",
       "    Failed example:\n",
       "        1 <= smallest_change_major <= 3\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "            ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                         compileflags, True), test.globs)\n",
       "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "          File \"<doctest q4_2 1[0]>\", line 1, in <module>\n",
       "            1 <= smallest_change_major <= 3\n",
       "                 ^^^^^^^^^^^^^^^^^^^^^\n",
       "        NameError: name 'smallest_change_major' is not defined\n",
       "</pre>"
      ],
      "text/plain": [
       "q4_2 results:\n",
       "    q4_2 - 1 result:\n",
       "         Test case failed\n",
       "        Trying:\n",
       "            isinstance(smallest_change_major, (int, float))\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q4_2 0\n",
       "        Failed example:\n",
       "            isinstance(smallest_change_major, (int, float))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q4_2 0[0]>\", line 1, in <module>\n",
       "                isinstance(smallest_change_major, (int, float))\n",
       "                           ^^^^^^^^^^^^^^^^^^^^^\n",
       "            NameError: name 'smallest_change_major' is not defined\n",
       "\n",
       "    q4_2 - 2 result:\n",
       "         Test case failed\n",
       "        Trying:\n",
       "            1 <= smallest_change_major <= 3\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q4_2 1\n",
       "        Failed example:\n",
       "            1 <= smallest_change_major <= 3\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q4_2 1[0]>\", line 1, in <module>\n",
       "                1 <= smallest_change_major <= 3\n",
       "                     ^^^^^^^^^^^^^^^^^^^^^\n",
       "            NameError: name 'smallest_change_major' is not defined"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eae797",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.**  For each major, define the relative change to be the following: $\\large{\\frac{\\text{absolute difference}}{\\text{value in 2008-2009}} * 100}$ \n",
    "\n",
    "Fill in the code below such that `gws_relative_change`, `linguistics_relative_change` and `rhetoric_relative_change` are assigned to the relative changes for their respective majors. **(5 Points)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dd882ec",
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student",
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for abs(): 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gws_relative_change \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m17\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      2\u001b[0m linguistics_relative_change \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m      3\u001b[0m rhetoric_relative_change \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for abs(): 'ellipsis'"
     ]
    }
   ],
   "source": [
    "gws_relative_change = (abs(...) / 17) * 100\n",
    "linguistics_relative_change = ...\n",
    "rhetoric_relative_change = ...\n",
    "gws_relative_change, linguistics_relative_change, rhetoric_relative_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aa37ca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef8132",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.** Assign `biggest_rel_change_major` to 1, 2, or 3 where each number corresponds to to the following: \n",
    "\n",
    "1. Gender and Women's Studies  \n",
    "2. Linguistics  \n",
    "3. Rhetoric\n",
    "\n",
    "Choose the number that corresponds to the major with the biggest relative change. **(4 Points)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25c166",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "biggest_rel_change_major = ...\n",
    "biggest_rel_change_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b34e5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb8772",
   "metadata": {},
   "source": [
    "## 5. Nearsightedness Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2086d84",
   "metadata": {},
   "source": [
    "[Myopia](https://en.wikipedia.org/wiki/Myopia), or nearsightedness, results from a number of genetic and environmental factors. In 1999, Quinn et al studied the relation between myopia and ambient lighting at night (for example, from nightlights or room lights) during childhood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa025f17",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 5.1.** The data were gathered by the following procedure, reported in the study. \"Between January and June 1998, parents of children aged 2-16 years [...] that were seen as outpatients in a university pediatric ophthalmology clinic completed a questionnaire on the child's light exposure both at present and before the age of 2 years.\" Was this study observational, or was it a controlled experiment? Explain. **(5 Points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584de720",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ad5c2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 5.2.** The study found that of the children who slept with a room light on before the age of 2, 55% were myopic. Of the children who slept with a night light on before the age of 2, 34% were myopic. Of the children who slept in the dark before the age of 2, 10% were myopic. The study concluded the following: \"The prevalence of myopia [...] during childhood was strongly associated with ambient light exposure during sleep at night in the first two years after birth.\"\n",
    "\n",
    "Do the data support this statement? Why or why not? You may interpret \"strongly\" in any reasonable qualitative way. **(5 Points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef65991",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa047e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 5.3.** On May 13, 1999, CNN reported the results of this study under the headline, \"Night light may lead to nearsightedness.\" Does the original study claim that night light causes nearsightedness? **(5 Points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6de1a1",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895dee6e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 5.4.** The final paragraph of the CNN report said that \"several eye specialists\" had pointed out that the study should have accounted for heredity.\n",
    "\n",
    "Myopia is passed down from parents to children. Myopic parents are more likely to have myopic children, and may also be more likely to leave lights on habitually (since the parents have poor vision). In what way does the knowledge of this possible genetic link affect how we interpret the data from the study? Explain. **(5 Points)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79750b",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313aebd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 6. Studying the Survivors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b106b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The Reverend Henry Whitehead was skeptical of John Snows conclusion about the Broad Street pump. After the Broad Street cholera epidemic ended, Whitehead set about trying to prove Snow wrong.  (The history of the event is detailed [here](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1034367/pdf/medhist00183-0026.pdf).)\n",
    "\n",
    "He realized that Snow had focused his analysis almost entirely on those who had died. Whitehead, therefore, investigated the drinking habits of people in the Broad Street area who had not died in the outbreak.\n",
    "\n",
    "What is the main reason it was important to study this group? Assign either 1, 2, or 3 to the name `survivor_answer` below. **(4 Points)**\n",
    "\n",
    "1. If Whitehead had found that many people had drunk water from the Broad Street pump and not caught cholera, that would have been evidence against Snow's hypothesis.\n",
    "\n",
    "2. Survivors could provide additional information about what else could have caused the cholera, potentially unearthing another cause.\n",
    "\n",
    "3. Through considering the survivors, Whitehead could have identified a cure for cholera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b4c06",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "survivor_answer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb59b5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad755f1",
   "metadata": {},
   "source": [
    "**Note:** Whitehead ended up finding further proof that the Broad Street pump played a central role in spreading the disease to the people who lived near it. Eventually, he became one of Snows greatest defenders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8c6a3",
   "metadata": {},
   "source": [
    "## 7. Policies and Administrivia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c522ba6",
   "metadata": {},
   "source": [
    "This section of the homework is to ensure that you have read over the policies and frequently asked questions for the course. \n",
    "\n",
    "**It's important that you read through this section of the homework very carefully**. If you can get through all of this section and are sure you have all of the correct resources set up, you will be able to focus on the actual material this semester!\n",
    "\n",
    "Reading through the [policies](http://data8.org/sp24/policies/) and the [FAQ](http://data8.org/sp24/faq/) will help you get through this section very easily. It is recommended you do this before proceeding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b302179",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** You have a question regarding the grading of your assignments that has not been previously answered on Ed or the FAQ. Who do you contact? Assign `contact` to the number corresponding to the best choice below. **(4 Points)**\n",
    "\n",
    "1. The Instructors\n",
    "2. Post on Ed\n",
    "3. Contact your Lab TA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0da6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contact = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637e7e9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69ae178",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Why are there typically 2 items listed on Gradescope for each homework assignment? Assign `grades` to the number corresponding to the best choice below. **(4 Points)**\n",
    "\n",
    "1. There was a mistake in the grading. I should contact someone about this.\n",
    "2. One assignment is for coding questions (which I will submit through a zip file), and the other is for written responses (which I will submit through a pdf).\n",
    "3. Trick question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aeb516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grades = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a76784",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb05cf80",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.** Regrade deadline dates will always be posted on the same Ed post that releases the assignment grades, common mistakes, and solutions. Can you ask for parts of your assignment regraded after the regrade request window has passed? Assign `regrade` to the number corresponding to the best choice below. **(4 Points)**\n",
    "\n",
    "1. Yes\n",
    "2. No\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd1a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regrade = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f07c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d90472",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.** Do you have an Gradescope account? Head to [gradescope.com](http://gradescope.com) and check if you see Data 8. If you do not, please send your Lab TA an email with your email and student ID number. \n",
    "\n",
    "Once you have been enrolled, go to the Data 8 Gradescope course website. At the end of the url link, you should see the six-digit number 703847. Assign `gradescope` to the integer 576157 if this is the case. **(4 Points)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7604a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gradescope = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b0c2e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa437eb2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.** Given the following scenarios, assign `acceptable` to the corresponding number of the scenario that is permissible given the guidelines on the [policies](http://data8.org/sp24/policies/) page. **(4 Points)**\n",
    "\n",
    "1. Jessica gets stuck on a homework assignment, so she googles a fix. She stumbles across a pdf of the solutions for the homework assignment from a previous semester's offering of Data 8. After inspecting the solution, Nicole writes her own solution and submits the assignment.\n",
    "\n",
    "2. After getting confused by a project, Atticus asks his friend for help. His friend Kelsey helps by walking Atticus through her own logic, without showing her code, pointing out areas that are important given the context of the question. Upon hearing his friend's logic, Atticus writes his own code and completes the project.\n",
    "\n",
    "3. Edwin (who is in a regular lab) has an extremely busy schedule, so he really wants to leave lab early by finishing it and getting checked off. His neighbor, Gamy, simply turns his computer so Edwin can see how he completed some questions. After looking at his code, Edwin finishes the lab and gets checked off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1efc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acceptable = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755b063",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd8da7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 6.** To make sure you have read through the [policies](http://data8.org/sp24/policies/) and the [FAQ](http://data8.org/sp24/faq/) carefully, how many HW and lab drops are there? Assign `drops` to the number corresponding to the best choice below. **(4 Points)**\n",
    "\n",
    "1. Two homework drops and three lab drops\n",
    "2. Two homework drops and two lab drops\n",
    "3. Only two homework drops\n",
    "4. One homework drop and two lab drops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ad8b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drops = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ade479",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e48c10",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 7.** Does Data 8 offer alternate final exam to those with class conflicts? Assign `exams` to the number corresponding to the best choice below. **(3 Points)**\n",
    "\n",
    "1. Yes\n",
    "2. No\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26895517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exams = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096dc55d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9ad156",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 8:** Are you actually checking Ed? Go to this semester's [Data 8 Ed](https://edstem.org/us/courses/52859/discussion/) and find an instructor posted thread with a certain secret phrase. Assign `secret` to this secret phrase in quotes (i.e. as a string). **(4 Points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898014a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "secret = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63604468",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579419be",
   "metadata": {},
   "source": [
    "## 8. Welcome Survey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "395bbb85",
   "metadata": {},
   "source": [
    "**Question 1.** Please complete the welcome survey below in order to receive credit for homework 1. Keep an eye out for the secret once} you submit! **(1 Point)**\n",
    "\n",
    "- [Spring 2024 Welcome Survey](https://docs.google.com/forms/d/e/1FAIpQLSfFNr9JCGMgF_N3tCz7gCzQP1y5Rxg8phSodVGTRwJo2Ds3hA/viewform?usp=sf_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d86743",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Assign `survey` to the secret phrase given at the end of the welcome survey. Make sure the phrase is in quotes (i.e. is a string)!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbebe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "survey = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06165ed0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f2a0950",
   "metadata": {},
   "source": [
    "You're done with Homework 1!  \n",
    "\n",
    "**Important submission information:** Be sure to run the tests and verify that they all pass, then choose **Save Notebook** from the **File** menu, then **run the final cell** and click the link to download the zip file. Then, go to [Gradescope](https://www.gradescope.com/courses/703847) and submit the zip file to the corresponding assignment. The name of this assignment is \"HW 01 Autograder\". **It is your responsibility to make sure your work is saved before running the last cell.**\n",
    "\n",
    "Once you have submitted, your Gradescope assignment should look something like the following image if you have passed all tests.\n",
    "\n",
    "**Note:** *This is a photo of a generic Gradescope submission result, and it does not included the same test numbers as this assignment. Please check that all test cases have passed for each question.*\n",
    "\n",
    "<img src=\"gradescope.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c07341e",
   "metadata": {},
   "source": [
    "## Pets of Data 8\n",
    "\n",
    "**Piper** say congrats on finishing Homework 1! We're excited for a great semester with you!\n",
    "\n",
    "<img src=\"./piper.jpg\" width=\"30%\" alt=\"Close up picture of dog sitting on wood path overlooking ocean.\"/>\n",
    "\n",
    "Pet of the week: **Piper**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed921363",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Below, you will see two cells. Running the first cell will automatically generate a PDF of all questions that need to be manually graded, and running the second cell will automatically generate a zip with your autograded answers. You are responsible for submitting both the coding portion (the zip) and the written portion (the PDF) to their respective Gradescope portals. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from otter.export import export_notebook\n",
    "from os import path\n",
    "from IPython.display import display, HTML\n",
    "export_notebook(\"hw01.ipynb\", filtering=True, pagebreaks=True)\n",
    "if(path.exists('hw01.pdf')):\n",
    "    display(HTML(\"Download your PDF <a href='hw01.pdf' download>here</a>.\"))\n",
    "else:\n",
    "    print(\"\\n Pdf generation fails, please try the other methods described above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3947fa00",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d3548",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q2_1": {
     "name": "q2_1",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 1 <= characters_q1 <= 5\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_2": {
     "name": "q2_2",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 1 <= characters_q2 <= 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_1": {
     "name": "q3_1",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 1 <= names_q1 <= 4\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_2": {
     "name": "q3_2",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 1 <= names_q2 <= 4\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_3": {
     "name": "q3_3",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 1 <= names_q3 <= 4\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_1": {
     "name": "q4_1",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(biggest_change, (int, float))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_2": {
     "name": "q4_2",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(smallest_change_major, (int, float))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 1 <= smallest_change_major <= 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_3": {
     "name": "q4_3",
     "points": [
      0,
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(gws_relative_change, (int, float))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(linguistics_relative_change, (int, float))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(rhetoric_relative_change, (int, float))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_4": {
     "name": "q4_4",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(biggest_rel_change_major, (int, float))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 1 <= biggest_rel_change_major <= 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6_1": {
     "name": "q6_1",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 1 <= survivor_answer <= 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7_1": {
     "name": "q7_1",
     "points": [
      4
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> contact == 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7_2": {
     "name": "q7_2",
     "points": [
      4
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> grades == 2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7_3": {
     "name": "q7_3",
     "points": [
      4
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> regrade == 2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7_4": {
     "name": "q7_4",
     "points": [
      4
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> gradescope == 576157\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7_5": {
     "name": "q7_5",
     "points": [
      4
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> acceptable == 2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7_6": {
     "name": "q7_6",
     "points": [
      4
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> drops == 2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7_7": {
     "name": "q7_7",
     "points": [
      3
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> exams == 2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7_8": {
     "name": "q7_8",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(secret) == str\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(secret)\n8",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8_1": {
     "name": "q8_1",
     "points": [
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> survey == 'data8 is data gr8'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
